{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Facebook, Inc. and its affiliates.\n",
    "#\n",
    "# This source code is licensed under the MIT license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\n",
    "import logging\n",
    "import math\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from fairseq.models import BaseFairseqModel, register_model, register_model_architecture\n",
    "from fairseq.modules import (\n",
    "    Fp32GroupNorm,\n",
    "    Fp32LayerNorm,\n",
    "    GumbelVectorQuantizer,\n",
    "    KmeansVectorQuantizer,\n",
    "    TransposeLast,\n",
    ")\n",
    "from fairseq.utils import buffered_arange\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class Wav2VecModel(BaseFairseqModel):\n",
    "    \n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "\n",
    "        self.prediction_steps = args.prediction_steps\n",
    "        offset = args.offset\n",
    "        activation = nn.ReLU()\n",
    "        \n",
    "        feature_enc_layers = eval(args.conv_feature_layers)\n",
    "        self.feature_extractor = Encoder(activation, 0.0)\n",
    "        embed = 512\n",
    "\n",
    "        jin = 0\n",
    "        rin = 0\n",
    "        for _, k, stride in feature_enc_layers:\n",
    "            if rin == 0:\n",
    "                rin = k\n",
    "            rin = rin + (k - 1) * jin\n",
    "            if jin == 0:\n",
    "                jin = stride\n",
    "            else:\n",
    "                jin *= stride\n",
    "        offset = math.ceil(rin / jin)\n",
    "\n",
    "        offset = int(offset)\n",
    "\n",
    "        def make_aggregator():\n",
    "            if args.aggregator == \"cnn\":\n",
    "                agg_layers = eval(args.conv_aggregator_layers)\n",
    "                agg_dim = agg_layers[-1][0]\n",
    "                feature_aggregator = ConvAggegator(\n",
    "                    conv_layers=agg_layers,\n",
    "                    embed=embed,\n",
    "                    dropout=args.dropout,\n",
    "                    skip_connections=args.skip_connections_agg,\n",
    "                    residual_scale=args.residual_scale,\n",
    "                    non_affine_group_norm=args.non_affine_group_norm,\n",
    "                    conv_bias=not args.no_conv_bias,\n",
    "                    zero_pad=args.agg_zero_pad,\n",
    "                    activation=activation,\n",
    "                )\n",
    "\n",
    "            return feature_aggregator, agg_dim\n",
    "\n",
    "        self.feature_aggregator, agg_dim = make_aggregator()\n",
    "\n",
    "        self.wav2vec_predictions = Wav2VecPredictionsModel(\n",
    "            in_dim=agg_dim,\n",
    "            out_dim=embed,\n",
    "            prediction_steps=args.prediction_steps,\n",
    "            n_negatives=args.num_negatives,\n",
    "            cross_sample_negatives=args.cross_sample_negatives,\n",
    "            sample_distance=args.sample_distance,\n",
    "            dropout=args.dropout,\n",
    "            offset=offset,\n",
    "            balanced_classes=args.balanced_classes,\n",
    "            infonce=args.infonce,\n",
    "        )\n",
    "\n",
    "        self.dropout_feats = nn.Dropout(p=args.dropout_features)\n",
    "        self.dropout_agg = nn.Dropout(p=args.dropout_agg)\n",
    "\n",
    "        if args.project_features == \"none\":\n",
    "            self.project_features = None\n",
    "        elif args.project_features == \"same\":\n",
    "            self.project_features = self.feature_aggregator\n",
    "        elif args.project_features == \"new\":\n",
    "            self.project_features, _ = make_aggregator()\n",
    "\n",
    "    def forward(self, source):\n",
    "        result = {}\n",
    "\n",
    "        features = self.feature_extractor(source)\n",
    "        if self.vector_quantizer:\n",
    "            q_res = self.vector_quantizer(features)\n",
    "            features = q_res[\"x\"]\n",
    "            for k in q_res.keys():\n",
    "                if k != \"x\":\n",
    "                    result[k] = q_res[k]\n",
    "\n",
    "        x = self.dropout_feats(features)\n",
    "        x = self.feature_aggregator(x)\n",
    "        x = self.dropout_agg(x)\n",
    "\n",
    "        if self.project_features is not None:\n",
    "            features = self.project_features(features)\n",
    "        # x = c\n",
    "        # features = z\n",
    "        x, targets = self.wav2vec_predictions(x, features)\n",
    "        result[\"cpc_logits\"] = x\n",
    "        result[\"cpc_targets\"] = targets\n",
    "\n",
    "        return result\n",
    "\n",
    "    def upgrade_state_dict_named(self, state_dict, name):\n",
    "        super().upgrade_state_dict_named(state_dict, name)\n",
    "\n",
    "    def max_positions(self):\n",
    "        \"\"\"Maximum length supported by the model.\"\"\"\n",
    "        return sys.maxsize\n",
    "\n",
    "    def get_logits(self, net_output):\n",
    "        logits = net_output[\"cpc_logits\"]\n",
    "        return logits\n",
    "\n",
    "    def get_targets(self, sample, net_output):\n",
    "        t = net_output[\"cpc_targets\"]\n",
    "        if isinstance(t, tuple):\n",
    "            t = t[0]\n",
    "        return t.contiguous()\n",
    "\n",
    "    def get_target_weights(self, targets, net_output):\n",
    "        targets = net_output[\"cpc_targets\"]\n",
    "        if isinstance(targets, tuple) and targets[-1] is not None:\n",
    "            return targets[-1]\n",
    "        return None\n",
    "\n",
    "    def get_extra_losses(self, net_output):\n",
    "        loss = None\n",
    "        if \"prob_perplexity\" in net_output:\n",
    "            loss = net_output[\"num_vars\"] - net_output[\"prob_perplexity\"]\n",
    "        elif \"kmeans_loss\" in net_output:\n",
    "            loss = net_output[\"kmeans_loss\"]\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "def norm_block(is_layer_norm, dim, affine=True):\n",
    "    if is_layer_norm:\n",
    "        mod = nn.Sequential(\n",
    "            TransposeLast(),\n",
    "            Fp32LayerNorm(dim, elementwise_affine=affine),\n",
    "            TransposeLast(),\n",
    "        )\n",
    "    else:\n",
    "        mod = Fp32GroupNorm(1, dim, affine=affine)\n",
    "\n",
    "    return mod\n",
    "\n",
    "class ZeroPad1d(nn.Module):\n",
    "    def __init__(self, pad_left, pad_right):\n",
    "        super().__init__()\n",
    "        self.pad_left = pad_left\n",
    "        self.pad_right = pad_right\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.pad(x, (self.pad_left, self.pad_right))\n",
    "\n",
    "\n",
    "class ConvAggegator(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        conv_layers,\n",
    "        embed,\n",
    "        dropout,\n",
    "        skip_connections,\n",
    "        residual_scale,\n",
    "        non_affine_group_norm,\n",
    "        conv_bias,\n",
    "        zero_pad,\n",
    "        activation,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        def block(n_in, n_out, k, stride):\n",
    "            # padding dims only really make sense for stride = 1\n",
    "            ka = k // 2\n",
    "            kb = ka - 1 if k % 2 == 0 else ka\n",
    "\n",
    "            pad = (\n",
    "                ZeroPad1d(ka + kb, 0) if zero_pad else nn.ReplicationPad1d((ka + kb, 0))\n",
    "            )\n",
    "\n",
    "            return nn.Sequential(\n",
    "                pad,\n",
    "                nn.Conv1d(n_in, n_out, k, stride=stride, bias=conv_bias),\n",
    "                nn.Dropout(p=dropout),\n",
    "                norm_block(False, n_out, affine=not non_affine_group_norm),\n",
    "                activation,\n",
    "            )\n",
    "\n",
    "        in_d = embed\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        self.residual_proj = nn.ModuleList()\n",
    "        for dim, k, stride in conv_layers:\n",
    "            if in_d != dim and skip_connections:\n",
    "                self.residual_proj.append(nn.Conv1d(in_d, dim, 1, bias=False))\n",
    "            else:\n",
    "                self.residual_proj.append(None)\n",
    "\n",
    "            self.conv_layers.append(block(in_d, dim, k, stride))\n",
    "            in_d = dim\n",
    "        self.conv_layers = nn.Sequential(*self.conv_layers)\n",
    "        self.skip_connections = skip_connections\n",
    "        self.residual_scale = math.sqrt(residual_scale)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for rproj, conv in zip(self.residual_proj, self.conv_layers):\n",
    "            residual = x\n",
    "            x = conv(x)\n",
    "            if self.skip_connections:\n",
    "                if rproj is not None:\n",
    "                    residual = rproj(residual)\n",
    "                x = (x + residual) * self.residual_scale\n",
    "        return x\n",
    "\n",
    "\n",
    "class Wav2VecPredictionsModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim,\n",
    "        out_dim,\n",
    "        prediction_steps,\n",
    "        n_negatives,\n",
    "        cross_sample_negatives,\n",
    "        sample_distance,\n",
    "        dropout,\n",
    "        offset,\n",
    "        balanced_classes,\n",
    "        infonce,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_negatives = n_negatives\n",
    "        self.cross_sample_negatives = cross_sample_negatives\n",
    "        self.sample_distance = sample_distance\n",
    "        self.project_to_steps = nn.ConvTranspose2d(\n",
    "            in_dim, out_dim, (1, prediction_steps)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.offset = offset\n",
    "        self.balanced_classes = balanced_classes\n",
    "        self.infonce = infonce\n",
    "\n",
    "    def sample_negatives(self, y):\n",
    "        bsz, fsz, tsz = y.shape\n",
    "\n",
    "        y = y.transpose(0, 1)  # BCT -> CBT\n",
    "        y = y.contiguous().view(fsz, -1)  # CBT => C(BxT)\n",
    "\n",
    "        cross_high = tsz * bsz\n",
    "        high = tsz if self.sample_distance is None else min(tsz, self.sample_distance)\n",
    "        assert high > 1\n",
    "\n",
    "        neg_idxs = torch.randint(low=0, high=high, size=(bsz, self.n_negatives * tsz))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if self.n_negatives > 0:\n",
    "                tszs = (\n",
    "                    buffered_arange(tsz)\n",
    "                    .unsqueeze(-1)\n",
    "                    .expand(-1, self.n_negatives)\n",
    "                    .flatten()\n",
    "                )\n",
    "\n",
    "                neg_idxs = torch.randint(\n",
    "                    low=0, high=high - 1, size=(bsz, self.n_negatives * tsz)\n",
    "                )\n",
    "                neg_idxs[neg_idxs >= tszs] += 1\n",
    "\n",
    "            if self.cross_sample_negatives > 0:\n",
    "                tszs = (\n",
    "                    buffered_arange(tsz)\n",
    "                    .unsqueeze(-1)\n",
    "                    .expand(-1, self.cross_sample_negatives)\n",
    "                    .flatten()\n",
    "                )\n",
    "\n",
    "                cross_neg_idxs = torch.randint(\n",
    "                    low=0,\n",
    "                    high=cross_high - 1,\n",
    "                    size=(bsz, self.cross_sample_negatives * tsz),\n",
    "                )\n",
    "                cross_neg_idxs[cross_neg_idxs >= tszs] += 1\n",
    "\n",
    "        if self.n_negatives > 0:\n",
    "            for i in range(1, bsz):\n",
    "                neg_idxs[i] += i * high\n",
    "        else:\n",
    "            neg_idxs = cross_neg_idxs\n",
    "\n",
    "        if self.cross_sample_negatives > 0 and self.n_negatives > 0:\n",
    "            neg_idxs = torch.cat([neg_idxs, cross_neg_idxs], dim=1)\n",
    "\n",
    "        negs = y[..., neg_idxs.view(-1)]\n",
    "        negs = negs.view(\n",
    "            fsz, bsz, self.n_negatives + self.cross_sample_negatives, tsz\n",
    "        ).permute(\n",
    "            2, 1, 0, 3\n",
    "        )  # to NxBxCxT\n",
    "\n",
    "        return negs\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # x = c\n",
    "        # y = z\n",
    "\n",
    "        x = x.unsqueeze(-1)\n",
    "\n",
    "        x = self.project_to_steps(x)  # BxCxTxS, batch, channels, sequence length, steps\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        negatives = self.sample_negatives(y)\n",
    "        y = y.unsqueeze(0)\n",
    "        targets = torch.cat([y, negatives], dim=0)  # Copies x B x C x T\n",
    "\n",
    "        copies = targets.size(0)\n",
    "        bsz, dim, tsz, steps = x.shape\n",
    "        steps = min(steps, tsz - self.offset)\n",
    "\n",
    "        predictions = x.new(\n",
    "            bsz * copies * (tsz - self.offset + 1) * steps\n",
    "            - ((steps + 1) * steps // 2) * copies * bsz\n",
    "        )\n",
    "        if self.infonce:\n",
    "            labels = predictions.new_full(\n",
    "                (predictions.shape[0] // copies,), 0, dtype=torch.long\n",
    "            )\n",
    "        else:\n",
    "            labels = torch.zeros_like(predictions)\n",
    "        weights = (\n",
    "            torch.full_like(labels, 1 / self.n_negatives)\n",
    "            if self.balanced_classes and not self.infonce\n",
    "            else None\n",
    "        )\n",
    "\n",
    "        start = end = 0\n",
    "        for i in range(steps):\n",
    "            offset = i + self.offset\n",
    "            end = start + (tsz - offset) * bsz * copies\n",
    "            if self.infonce:\n",
    "                predictions[start:end] = torch.einsum(\n",
    "                    \"bct,nbct->tbn\", x[..., :-offset, i], targets[..., offset:]\n",
    "                ).flatten()\n",
    "            else:\n",
    "                pos_num = (end - start) // copies\n",
    "                predictions[start:end] = torch.einsum(\n",
    "                    \"bct,nbct->nbt\", x[..., :-offset, i], targets[..., offset:]\n",
    "                ).flatten()\n",
    "                labels[start : start + pos_num] = 1.0\n",
    "                if weights is not None:\n",
    "                    weights[start : start + pos_num] = 1.0\n",
    "            start = end\n",
    "        assert end == predictions.numel(), \"{} != {}\".format(end, predictions.numel())\n",
    "\n",
    "        if self.infonce:\n",
    "            predictions = predictions.view(-1, copies)\n",
    "        else:\n",
    "            if weights is not None:\n",
    "                labels = (labels, weights)\n",
    "\n",
    "        return predictions, labels\n",
    "\n",
    "\n",
    "@register_model_architecture(\"wav2vec\", \"wav2vec\")\n",
    "def base_wav2vec_architecture(args):\n",
    "    conv_feature_layers = \"[(512, 10, 5)]\"\n",
    "    conv_feature_layers += \" + [(512, 8, 4)]\"\n",
    "    conv_feature_layers += \" + [(512, 4, 2)] * 3\"\n",
    "    args.conv_feature_layers = getattr(args, \"conv_feature_layers\", conv_feature_layers)\n",
    "\n",
    "    args.conv_aggregator_layers = getattr(\n",
    "        args, \"conv_aggregator_layers\", \"[(512, 3, 1)] * 9\"\n",
    "    )\n",
    "\n",
    "    args.prediction_steps = getattr(args, \"prediction_steps\", 12)\n",
    "    args.num_negatives = getattr(args, \"num_negatives\", 1)\n",
    "    args.sample_distance = getattr(args, \"sample_distance\", None)\n",
    "    args.cross_sample_negatives = getattr(args, \"cross_sample_negatives\", 0)\n",
    "\n",
    "    args.dropout = getattr(args, \"dropout\", 0.0)\n",
    "    args.dropout_features = getattr(args, \"dropout_features\", 0.0)\n",
    "    args.dropout_agg = getattr(args, \"dropout_agg\", 0.0)\n",
    "    args.encoder = getattr(args, \"encoder\", \"cnn\")\n",
    "    args.aggregator = getattr(args, \"aggregator\", \"cnn\")\n",
    "\n",
    "    args.skip_connections_feat = getattr(args, \"skip_connections_feat\", False)\n",
    "    args.skip_connections_agg = getattr(args, \"skip_connections_agg\", False)\n",
    "    args.residual_scale = getattr(args, \"residual_scale\", 0.5)\n",
    "\n",
    "    args.gru_dim = getattr(args, \"gru_dim\", 512)\n",
    "\n",
    "    args.no_conv_bias = getattr(args, \"no_conv_bias\", False)\n",
    "    args.agg_zero_pad = getattr(args, \"agg_zero_pad\", False)\n",
    "\n",
    "    args.log_compression = getattr(args, \"log_compression\", False)\n",
    "\n",
    "    args.balanced_classes = getattr(args, \"balanced_classes\", False)\n",
    "    args.infonce = getattr(args, \"infonce\", False)\n",
    "    args.project_features = getattr(args, \"project_features\", \"none\")\n",
    "\n",
    "    args.non_affine_group_norm = getattr(args, \"non_affine_group_norm\", False)\n",
    "\n",
    "    args.offset = getattr(args, \"offset\", \"auto\")\n",
    "\n",
    "    args.activation = getattr(args, \"activation\", \"relu\")\n",
    "\n",
    "    args.vq_type = getattr(args, \"vq_type\", \"none\")\n",
    "    args.vq_vars = getattr(args, \"vq_vars\", 320)\n",
    "    args.vq_groups = getattr(args, \"vq_groups\", 2)\n",
    "    args.vq_dim = getattr(args, \"vq_dim\", 0)\n",
    "    args.vq_depth = getattr(args, \"vq_depth\", 1)\n",
    "    args.combine_groups = getattr(args, \"combine_groups\", False)\n",
    "    args.vq_temp = getattr(args, \"vq_temp\", \"(2.0, 0.5, 0.999995)\")\n",
    "    args.vq_gamma = getattr(args, \"vq_gamma\", 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6c65a2d11563>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, activation, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.in_c = 10\n",
    "        \n",
    "        # Hardcoded architecture, as the blocks are different\n",
    "        self.encoder = nn.Sequential(nn.Conv1d(in_channels=1, out_channels=self.in_c, kernel_size=10, stride=5),\n",
    "                                     nn.Dropout(p=dropout),\n",
    "                                     nn.GroupNorm(1, self.in_c),  # Affine, what to do?\n",
    "                                     activation,\n",
    "                                     # 2nd layer\n",
    "                                     nn.Conv1d(in_channels=self.in_c, out_channels=self.in_c, kernel_size=8, stride=4),\n",
    "                                     nn.Dropout(p=dropout),\n",
    "                                     ## See norm_block - FB_repo\n",
    "                                     nn.GroupNorm(1, self.in_c),  # Affine, what to do?\n",
    "                                     activation,\n",
    "                                     # 3rd layer\n",
    "                                     nn.Conv1d(in_channels=self.in_c, out_channels=self.in_c, kernel_size=4, stride=2),\n",
    "                                     nn.Dropout(p=dropout),\n",
    "                                     nn.GroupNorm(1, self.in_c),  # Affine, what to do?\n",
    "                                     activation,\n",
    "                                     # Fourth layer\n",
    "                                     nn.Conv1d(in_channels=self.in_c, out_channels=self.in_c, kernel_size=4, stride=2),\n",
    "                                     nn.Dropout(p=dropout),\n",
    "                                     nn.GroupNorm(1, self.in_c),  # Affine, what to do?\n",
    "                                     activation,\n",
    "                                     # Fifth layer\n",
    "                                     nn.Conv1d(in_channels=self.in_c, out_channels=self.in_c, kernel_size=4, stride=2),\n",
    "                                     nn.Dropout(p=dropout),\n",
    "                                     nn.GroupNorm(1, self.in_c),  # Affine, what to do?\n",
    "                                     activation)\n",
    "    def log_compression(self, x):\n",
    "        # https://www.edn.com/log-1-x-compression/\n",
    "        x = x.abs()\n",
    "        x = x + 1\n",
    "        return x.log()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.log_compression(x)\n",
    "        # TODO implement skipped connections?\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
